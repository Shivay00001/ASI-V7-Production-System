# ASI Brain System - Complete Proof of Concept Implementation
# Free & Open Source Implementation using Transformers, PyTorch, and Hugging Face

import torch
import torch.nn as nn
import torch.nn.functional as F
from transformers import AutoModel, AutoTokenizer, AutoConfig
import numpy as np
import json
import logging
from datetime import datetime
from typing import Dict, List, Tuple, Optional, Any
import sqlite3
import asyncio
from dataclasses import dataclass
from abc import ABC, abstractmethod
import hashlib
import pickle
from pathlib import Path

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Core Data Structures
@dataclass
class ReasoningStep:
    step_id: str
    reasoning_type: str  # logical, critical, computational, intuitive
    input_data: Any
    output_data: Any
    confidence: float
    sources: List[str]
    timestamp: datetime
    explanation: str

@dataclass
class KnowledgeNode:
    node_id: str
    content: str
    domain: str
    confidence: float
    sources: List[str]
    last_updated: datetime
    connections: List[str]

class CognitiveProcessingEngine(nn.Module):
    """
    Advanced Cognitive Processing Engine with Multi-dimensional Reasoning
    Free implementation using Transformers and custom neural layers
    """
    
    def __init__(self, config: Dict):
        super().__init__()
        self.config = config
        
        # Base transformer model (free from Hugging Face)
        model_name = config.get('base_model', 'microsoft/DialoGPT-medium')
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        self.base_model = AutoModel.from_pretrained(model_name)
        
        # Add padding token if not present
        if self.tokenizer.pad_token is None:
            self.tokenizer.pad_token = self.tokenizer.eos_token
        
        # Multi-dimensional reasoning layers
        self.hidden_size = self.base_model.config.hidden_size
        
        # Reasoning Stream Processors
        self.logical_processor = nn.Sequential(
            nn.Linear(self.hidden_size, self.hidden_size * 2),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(self.hidden_size * 2, self.hidden_size),
            nn.LayerNorm(self.hidden_size)
        )
        
        self.critical_processor = nn.Sequential(
            nn.Linear(self.hidden_size, self.hidden_size * 2),
            nn.GELU(),
            nn.Dropout(0.1),
            nn.Linear(self.hidden_size * 2, self.hidden_size),
            nn.LayerNorm(self.hidden_size)
        )
        
        self.computational_processor = nn.Sequential(
            nn.Linear(self.hidden_size, self.hidden_size * 2),
            nn.SiLU(),
            nn.Dropout(0.1),
            nn.Linear(self.hidden_size * 2, self.hidden_size),
            nn.LayerNorm(self.hidden_size)
        )
        
        self.intuitive_processor = nn.Sequential(
            nn.Linear(self.hidden_size, self.hidden_size * 2),
            nn.Tanh(),
            nn.Dropout(0.1),
            nn.Linear(self.hidden_size * 2, self.hidden_size),
            nn.LayerNorm(self.hidden_size)
        )
        
        # Dynamic Weight Allocation Network
        self.weight_allocator = nn.Sequential(
            nn.Linear(self.hidden_size, 128),
            nn.ReLU(),
            nn.Linear(128, 4),  # 4 reasoning types
            nn.Softmax(dim=-1)
        )
        
        # Cross-stream Synthesis
        self.synthesis_layer = nn.MultiheadAttention(
            embed_dim=self.hidden_size,
            num_heads=8,
            dropout=0.1
        )
        
        # Output projection
        self.output_projection = nn.Linear(self.hidden_size, self.tokenizer.vocab_size)
        
        # Confidence estimation
        self.confidence_estimator = nn.Sequential(
            nn.Linear(self.hidden_size, 64),
            nn.ReLU(),
            nn.Linear(64, 1),
            nn.Sigmoid()
        )
    
    def forward(self, input_ids, attention_mask=None, problem_type=None):
        """
        Forward pass with multi-dimensional reasoning
        """
        # Get base embeddings
        outputs = self.base_model(input_ids=input_ids, attention_mask=attention_mask)
        hidden_states = outputs.last_hidden_state
        
        # Apply different reasoning processors
        logical_out = self.logical_processor(hidden_states)
        critical_out = self.critical_processor(hidden_states)
        computational_out = self.computational_processor(hidden_states)
        intuitive_out = self.intuitive_processor(hidden_states)
        
        # Dynamic weight allocation
        pooled_hidden = hidden_states.mean(dim=1)  # Global average pooling
        weights = self.weight_allocator(pooled_hidden).unsqueeze(1)
        
        # Weighted combination
        combined = (weights[:, :, 0:1] * logical_out + 
                   weights[:, :, 1:2] * critical_out +
                   weights[:, :, 2:3] * computational_out + 
                   weights[:, :, 3:4] * intuitive_out)
        
        # Cross-stream synthesis using attention
        synthesized, attention_weights = self.synthesis_layer(
            combined.transpose(0, 1),
            combined.transpose(0, 1),
            combined.transpose(0, 1)
        )
        synthesized = synthesized.transpose(0, 1)
        
        # Output projection
        logits = self.output_projection(synthesized)
        
        # Confidence estimation
        confidence = self.confidence_estimator(pooled_hidden)
        
        return {
            'logits': logits,
            'hidden_states': synthesized,
            'reasoning_weights': weights,
            'confidence': confidence,
            'attention_weights': attention_weights
        }

class RealTimeLearningEngine:
    """
    Real-time learning with knowledge graph integration
    Uses SQLite for free local storage
    """
    
    def __init__(self, db_path: str = "asi_knowledge.db"):
        self.db_path = db_path
        self.init_database()
        
    def init_database(self):
        """Initialize knowledge database"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # Knowledge nodes table
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS knowledge_nodes (
                node_id TEXT PRIMARY KEY,
                content TEXT,
                domain TEXT,
                confidence REAL,
                sources TEXT,
                last_updated TIMESTAMP,
                connections TEXT
            )
        ''')
        
        # Learning events table
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS learning_events (
                event_id TEXT PRIMARY KEY,
                event_type TEXT,
                input_data TEXT,
                output_data TEXT,
                feedback_score REAL,
                timestamp TIMESTAMP
            )
        ''')
        
        conn.commit()
        conn.close()
    
    def update_knowledge(self, content: str, domain: str, sources: List[str], confidence: float = 0.8):
        """Add or update knowledge without catastrophic forgetting"""
        node_id = hashlib.md5(content.encode()).hexdigest()
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # Check if knowledge exists
        cursor.execute('SELECT * FROM knowledge_nodes WHERE node_id = ?', (node_id,))
        existing = cursor.fetchone()
        
        if existing:
            # Update with weighted averaging to prevent forgetting
            old_confidence = existing[3]
            new_confidence = (old_confidence * 0.7 + confidence * 0.3)  # Weighted update
            
            cursor.execute('''
                UPDATE knowledge_nodes 
                SET confidence = ?, sources = ?, last_updated = ?
                WHERE node_id = ?
            ''', (new_confidence, json.dumps(sources), datetime.now(), node_id))
        else:
            # Add new knowledge
            cursor.execute('''
                INSERT INTO knowledge_nodes 
                (node_id, content, domain, confidence, sources, last_updated, connections)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            ''', (node_id, content, domain, confidence, json.dumps(sources), datetime.now(), '[]'))
        
        conn.commit()
        conn.close()
        
        logger.info(f"Updated knowledge: {content[:50]}... (confidence: {confidence})")
    
    def retrieve_knowledge(self, query: str, domain: str = None, top_k: int = 5) -> List[KnowledgeNode]:
        """Retrieve relevant knowledge based on query"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        if domain:
            cursor.execute('''
                SELECT * FROM knowledge_nodes 
                WHERE domain = ? AND content LIKE ?
                ORDER BY confidence DESC LIMIT ?
            ''', (domain, f'%{query}%', top_k))
        else:
            cursor.execute('''
                SELECT * FROM knowledge_nodes 
                WHERE content LIKE ?
                ORDER BY confidence DESC LIMIT ?
            ''', (f'%{query}%', top_k))
        
        results = cursor.fetchall()
        conn.close()
        
        knowledge_nodes = []
        for row in results:
            node = KnowledgeNode(
                node_id=row[0],
                content=row[1],
                domain=row[2],
                confidence=row[3],
                sources=json.loads(row[4]),
                last_updated=datetime.fromisoformat(row[5]),
                connections=json.loads(row[6])
            )
            knowledge_nodes.append(node)
        
        return knowledge_nodes

class TransparentDecisionMaking:
    """
    Explainable AI framework for transparent decision making
    """
    
    def __init__(self):
        self.reasoning_trace = []
        self.source_attribution = {}
        self.confidence_scores = {}
        self.alternative_paths = []
    
    def log_reasoning_step(self, step: ReasoningStep):
        """Log each reasoning step for transparency"""
        self.reasoning_trace.append(step)
        logger.info(f"Reasoning step: {step.reasoning_type} - {step.explanation}")
    
    def explain_decision(self, query: str) -> Dict:
        """Generate comprehensive explanation of decision process"""
        return {
            'query': query,
            'reasoning_steps': [
                {
                    'step_id': step.step_id,
                    'type': step.reasoning_type,
                    'explanation': step.explanation,
                    'confidence': step.confidence,
                    'sources': step.sources,
                    'timestamp': step.timestamp.isoformat()
                }
                for step in self.reasoning_trace
            ],
            'sources_used': self.source_attribution,
            'confidence_levels': self.confidence_scores,
            'alternative_approaches': self.alternative_paths,
            'uncertainty_factors': self.identify_uncertainties()
        }
    
    def identify_uncertainties(self) -> List[str]:
        """Identify sources of uncertainty in reasoning"""
        uncertainties = []
        
        # Low confidence steps
        low_conf_steps = [step for step in self.reasoning_trace if step.confidence < 0.7]
        if low_conf_steps:
            uncertainties.append(f"Low confidence in {len(low_conf_steps)} reasoning steps")
        
        # Missing sources
        steps_without_sources = [step for step in self.reasoning_trace if not step.sources]
        if steps_without_sources:
            uncertainties.append(f"{len(steps_without_sources)} steps lack source attribution")
        
        # Conflicting reasoning types
        reasoning_types = [step.reasoning_type for step in self.reasoning_trace]
        if len(set(reasoning_types)) > 2:
            uncertainties.append("Multiple reasoning approaches used - potential conflicts")
        
        return uncertainties

class SafetyAndAlignment:
    """
    Safety monitoring and alignment framework
    """
    
    def __init__(self):
        self.safety_checks = []
        self.bias_detection = BiasDetector()
        self.harm_prevention = HarmPrevention()
    
    def evaluate_safety(self, input_text: str, output_text: str) -> Dict:
        """Comprehensive safety evaluation"""
        safety_report = {
            'input_safe': True,
            'output_safe': True,
            'bias_detected': False,
            'harm_risk': 'low',
            'recommendations': []
        }
        
        # Bias detection
        bias_score = self.bias_detection.detect_bias(output_text)
        if bias_score > 0.5:
            safety_report['bias_detected'] = True
            safety_report['recommendations'].append("Review output for potential bias")
        
        # Harm prevention
        harm_score = self.harm_prevention.assess_harm(output_text)
        if harm_score > 0.3:
            safety_report['harm_risk'] = 'medium'
            safety_report['recommendations'].append("Human review recommended")
        
        return safety_report

class BiasDetector:
    """Simple bias detection using keyword analysis"""
    
    def __init__(self):
        # Simple bias keywords (in real implementation, use ML models)
        self.bias_keywords = [
            'always', 'never', 'all', 'none', 'every', 'typical', 'natural', 'obvious'
        ]
    
    def detect_bias(self, text: str) -> float:
        """Simple bias detection score"""
        words = text.lower().split()
        bias_count = sum(1 for word in words if word in self.bias_keywords)
        return min(bias_count / len(words) * 10, 1.0) if words else 0.0

class HarmPrevention:
    """Basic harm prevention assessment"""
    
    def __init__(self):
        self.harmful_categories = [
            'violence', 'illegal', 'harmful', 'dangerous', 'toxic'
        ]
    
    def assess_harm(self, text: str) -> float:
        """Simple harm assessment score"""
        text_lower = text.lower()
        harm_indicators = sum(1 for category in self.harmful_categories if category in text_lower)
        return min(harm_indicators / 10, 1.0)

class BenchmarkEvaluator:
    """
    Benchmark evaluation framework for validation
    """
    
    def __init__(self):
        self.benchmarks = {
            'logic_reasoning': self.logic_reasoning_test,
            'reading_comprehension': self.reading_comprehension_test,
            'mathematical_reasoning': self.mathematical_reasoning_test,
            'common_sense': self.common_sense_test,
            'ethical_reasoning': self.ethical_reasoning_test
        }
    
    def logic_reasoning_test(self) -> Dict:
        """Simple logic reasoning test"""
        questions = [
            {"question": "If all cats are animals and Fluffy is a cat, is Fluffy an animal?", "answer": "yes"},
            {"question": "If it's raining and I don't have an umbrella, will I get wet?", "answer": "yes"},
            {"question": "If A > B and B > C, is A > C?", "answer": "yes"}
        ]
        
        return {
            'total_questions': len(questions),
            'questions': questions,
            'benchmark_type': 'logic_reasoning'
        }
    
    def reading_comprehension_test(self) -> Dict:
        """Reading comprehension test"""
        passages = [
            {
                "passage": "The cat sat on the mat. The cat was black and white.",
                "question": "What color was the cat?",
                "answer": "black and white"
            }
        ]
        
        return {
            'total_questions': len(passages),
            'questions': passages,
            'benchmark_type': 'reading_comprehension'
        }
    
    def mathematical_reasoning_test(self) -> Dict:
        """Mathematical reasoning test"""
        problems = [
            {"problem": "What is 2 + 2?", "answer": "4"},
            {"problem": "If John has 3 apples and gives away 1, how many does he have?", "answer": "2"}
        ]
        
        return {
            'total_questions': len(problems),
            'questions': problems,
            'benchmark_type': 'mathematical_reasoning'
        }
    
    def common_sense_test(self) -> Dict:
        """Common sense reasoning test"""
        questions = [
            {"question": "What do you use to write on paper?", "answer": "pen or pencil"},
            {"question": "Where do fish live?", "answer": "water"}
        ]
        
        return {
            'total_questions': len(questions),
            'questions': questions,
            'benchmark_type': 'common_sense'
        }
    
    def ethical_reasoning_test(self) -> Dict:
        """Ethical reasoning test"""
        scenarios = [
            {
                "scenario": "You find a wallet on the street. What should you do?",
                "options": ["Keep it", "Return it to owner", "Give to police"],
                "correct": "Return it to owner"
            }
        ]
        
        return {
            'total_questions': len(scenarios),
            'questions': scenarios,
            'benchmark_type': 'ethical_reasoning'
        }
    
    def run_all_benchmarks(self) -> Dict:
        """Run all benchmark tests"""
        results = {}
        for name, test_func in self.benchmarks.items():
            results[name] = test_func()
        
        return {
            'timestamp': datetime.now().isoformat(),
            'benchmarks': results,
            'total_benchmarks': len(self.benchmarks)
        }

class ASIBrainSystem:
    """
    Main ASI Brain System integrating all components
    """
    
    def __init__(self, config: Dict = None):
        if config is None:
            config = {
                'base_model': 'microsoft/DialoGPT-medium',
                'max_length': 512,
                'temperature': 0.7,
                'top_p': 0.9
            }
        
        self.config = config
        
        # Initialize components
        print("Initializing ASI Brain System...")
        self.cognitive_engine = CognitiveProcessingEngine(config)
        self.learning_engine = RealTimeLearningEngine()
        self.decision_maker = TransparentDecisionMaking()
        self.safety_monitor = SafetyAndAlignment()
        self.benchmark_evaluator = BenchmarkEvaluator()
        
        print("ASI Brain System initialized successfully!")
    
    def process_query(self, query: str, context: str = None) -> Dict:
        """
        Main query processing with full ASI capabilities
        """
        logger.info(f"Processing query: {query}")
        
        # Safety check input
        safety_report = self.safety_monitor.evaluate_safety(query, "")
        if not safety_report['input_safe']:
            return {'error': 'Input failed safety check', 'safety_report': safety_report}
        
        # Tokenize input
        inputs = self.cognitive_engine.tokenizer(
            query, 
            return_tensors='pt',
            max_length=self.config['max_length'],
            truncation=True,
            padding=True
        )
        
        # Generate response using cognitive engine
        with torch.no_grad():
            outputs = self.cognitive_engine(**inputs)
        
        # Decode response
        generated_ids = torch.argmax(outputs['logits'], dim=-1)
        response = self.cognitive_engine.tokenizer.decode(generated_ids[0], skip_special_tokens=True)
        
        # Log reasoning step
        reasoning_step = ReasoningStep(
            step_id=hashlib.md5(query.encode()).hexdigest()[:8],
            reasoning_type="multi_dimensional",
            input_data=query,
            output_data=response,
            confidence=float(outputs['confidence'][0]),
            sources=["cognitive_processing_engine"],
            timestamp=datetime.now(),
            explanation=f"Applied multi-dimensional reasoning with weights: {outputs['reasoning_weights'][0].tolist()}"
        )
        self.decision_maker.log_reasoning_step(reasoning_step)
        
        # Retrieve relevant knowledge
        knowledge_nodes = self.learning_engine.retrieve_knowledge(query)
        
        # Safety check output
        output_safety = self.safety_monitor.evaluate_safety(query, response)
        
        # Update knowledge base
        self.learning_engine.update_knowledge(
            content=f"Q: {query} A: {response}",
            domain="general",
            sources=["user_interaction"],
            confidence=float(outputs['confidence'][0])
        )
        
        return {
            'query': query,
            'response': response,
            'confidence': float(outputs['confidence'][0]),
            'reasoning_weights': outputs['reasoning_weights'][0].tolist(),
            'knowledge_retrieved': len(knowledge_nodes),
            'safety_report': output_safety,
            'explanation': self.decision_maker.explain_decision(query),
            'timestamp': datetime.now().isoformat()
        }
    
    def train_on_feedback(self, query: str, response: str, feedback_score: float):
        """
        Learn from human feedback
        """
        logger.info(f"Learning from feedback: {feedback_score}")
        
        # Update knowledge with feedback
        self.learning_engine.update_knowledge(
            content=f"Q: {query} A: {response}",
            domain="feedback_learning",
            sources=["human_feedback"],
            confidence=feedback_score
        )
        
        # Log learning event
        conn = sqlite3.connect(self.learning_engine.db_path)
        cursor = conn.cursor()
        
        event_id = hashlib.md5(f"{query}{response}{feedback_score}".encode()).hexdigest()
        cursor.execute('''
            INSERT OR REPLACE INTO learning_events 
            (event_id, event_type, input_data, output_data, feedback_score, timestamp)
            VALUES (?, ?, ?, ?, ?, ?)
        ''', (event_id, "feedback_learning", query, response, feedback_score, datetime.now()))
        
        conn.commit()
        conn.close()
        
        return {"status": "feedback_processed", "event_id": event_id}
    
    def run_benchmarks(self) -> Dict:
        """
        Run comprehensive benchmark evaluation
        """
        logger.info("Running benchmark evaluation...")
        
        benchmark_results = self.benchmark_evaluator.run_all_benchmarks()
        
        # Test system on each benchmark
        system_performance = {}
        
        for benchmark_name, benchmark_data in benchmark_results['benchmarks'].items():
            correct_answers = 0
            total_questions = benchmark_data['total_questions']
            
            for question_data in benchmark_data['questions']:
                # Extract question based on benchmark type
                if 'question' in question_data:
                    question = question_data['question']
                elif 'problem' in question_data:
                    question = question_data['problem']
                elif 'scenario' in question_data:
                    question = question_data['scenario']
                else:
                    continue
                
                # Get system response
                result = self.process_query(question)
                system_response = result['response'].lower()
                
                # Check if answer is correct (simple string matching)
                correct_answer = question_data.get('answer', '').lower()
                if correct_answer in system_response:
                    correct_answers += 1
            
            accuracy = correct_answers / total_questions if total_questions > 0 else 0
            system_performance[benchmark_name] = {
                'accuracy': accuracy,
                'correct': correct_answers,
                'total': total_questions
            }
        
        return {
            'benchmark_results': benchmark_results,
            'system_performance': system_performance,
            'overall_accuracy': np.mean([perf['accuracy'] for perf in system_performance.values()]),
            'timestamp': datetime.now().isoformat()
        }
    
    def get_system_stats(self) -> Dict:
        """Get comprehensive system statistics"""
        conn = sqlite3.connect(self.learning_engine.db_path)
        cursor = conn.cursor()
        
        # Knowledge base stats
        cursor.execute('SELECT COUNT(*) FROM knowledge_nodes')
        total_knowledge = cursor.fetchone()[0]
        
        cursor.execute('SELECT AVG(confidence) FROM knowledge_nodes')
        avg_confidence = cursor.fetchone()[0] or 0
        
        # Learning events stats
        cursor.execute('SELECT COUNT(*) FROM learning_events')
        total_learning_events = cursor.fetchone()[0]
        
        cursor.execute('SELECT AVG(feedback_score) FROM learning_events WHERE event_type = "feedback_learning"')
        avg_feedback_score = cursor.fetchone()[0] or 0
        
        conn.close()
        
        return {
            'knowledge_base': {
                'total_nodes': total_knowledge,
                'average_confidence': avg_confidence
            },
            'learning_stats': {
                'total_events': total_learning_events,
                'average_feedback_score': avg_feedback_score
            },
            'reasoning_steps': len(self.decision_maker.reasoning_trace),
            'system_uptime': datetime.now().isoformat(),
            'model_parameters': sum(p.numel() for p in self.cognitive_engine.parameters()),
            'memory_usage': f"{torch.cuda.memory_allocated() / 1024**2:.2f} MB" if torch.cuda.is_available() else "CPU only"
        }

# Demo and Testing Functions
def demo_asi_system():
    """
    Demonstration of ASI Brain System capabilities
    """
    print("ðŸ§  ASI Brain System Demo Starting...")
    print("=" * 50)
    
    # Initialize system
    asi_system = ASIBrainSystem()
    
    # Demo queries
    demo_queries = [
        "What is artificial intelligence?",
        "Explain quantum computing in simple terms",
        "How can I solve climate change?",
        "What is 2 + 2 and why?",
        "Should I tell the truth if it hurts someone?"
    ]
    
    print("\nðŸ” Testing Query Processing:")
    for i, query in enumerate(demo_queries, 1):
        print(f"\n{i}. Query: {query}")
        result = asi_system.process_query(query)
        print(f"   Response: {result['response']}")
        print(f"   Confidence: {result['confidence']:.3f}")
        print(f"   Safety Status: {'âœ… Safe' if result['safety_report']['output_safe'] else 'âš ï¸ Unsafe'}")
    
    print("\nðŸ“Š Running Benchmark Evaluation:")
    benchmark_results = asi_system.run_benchmarks()
    print(f"Overall Accuracy: {benchmark_results['overall_accuracy']:.3f}")
    
    for benchmark, performance in benchmark_results['system_performance'].items():
        print(f"  {benchmark}: {performance['accuracy']:.3f} ({performance['correct']}/{performance['total']})")
    
    print("\nðŸ“ˆ System Statistics:")
    stats = asi_system.get_system_stats()
    print(f"  Knowledge Nodes: {stats['knowledge_base']['total_nodes']}")
    print(f"  Average Confidence: {stats['knowledge_base']['average_confidence']:.3f}")
    print(f"  Model Parameters: {stats['model_parameters']:,}")
    print(f"  Memory Usage: {stats['memory_usage']}")
    
    print("\nðŸŽ¯ Testing Feedback Learning:")
    feedback_result = asi_system.train_on_feedback(
        "What is AI?", 
        "AI is artificial intelligence", 
        0.9
    )
    print(f"  Feedback processed: {feedback_result['status']}")
    
    print("\nâœ… Demo completed successfully!")
    print("=" * 50)
    
    return asi_system

# Main execution
if __name__ == "__main__":
    # Run the demo
    system = demo_asi_system()
    
    # Interactive mode
    print("\nðŸ¤– Interactive ASI Brain System")
    print("Type 'quit' to exit, 'stats' for system stats, 'benchmark' to run tests")
    
    while True:
        try:
            user_input = input("\nYou: ").strip()
            
            if user_input.lower() == 'quit':
                break
            elif user_input.lower() == 'stats':
                stats = system.get_system_stats()
                print(f"ðŸ“Š System Stats: {json.dumps(stats, indent=2)}")
            elif user_input.lower() == 'benchmark':
                results = system.run_benchmarks()
                print(f"ðŸ“‹ Benchmark Results: Overall Accuracy = {results['overall_accuracy']:.3f}")
            elif user_input:
                result = system.process_query(user_input)
                print(f"ASI: {result['response']}")
                print(f"(Confidence: {result['confidence']:.3f})")
                
                # Ask for feedback
                feedback = input("Rate response (0-1): ").strip()
                if feedback:
                    try:
                        score = float(feedback)
                        system.train_on_feedback(user_input, result['response'], score)
                        print("âœ… Feedback recorded!")
                    except ValueError:
                        pass
            
            # New command for training
            elif user_input.lower().startswith('train '):
                file_path = user_input[6:].strip()
                if os.path.exists(file_path):
                    print(f"ðŸš€ Starting training on {file_path}...")
                    try:
                        train_stats = system.fine_tune_on_data(file_path)
                        print(f"âœ… Training completed! Final Loss: {train_stats['final_loss']:.4f}")
                    except Exception as e:
                        print(f"âŒ Training failed: {e}")
                else:
                    print("âŒ File not found.")

class TextDataset(torch.utils.data.Dataset):
    """Simple dataset for text training"""
    def __init__(self, file_path, tokenizer, block_size=128):
        self.examples = []
        with open(file_path, 'r', encoding='utf-8') as f:
            text = f.read()
            
        tokenized_text = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text))
        
        # Create blocks
        for i in range(0, len(tokenized_text) - block_size + 1, block_size):
            self.examples.append(tokenizer.build_inputs_with_special_tokens(tokenized_text[i:i + block_size]))

    def __len__(self):
        return len(self.examples)

    def __getitem__(self, item):
        return torch.tensor(self.examples[item], dtype=torch.long)

class ASITrainer:
    """Trainer for fine-tuning the ASI model"""
    def __init__(self, model, tokenizer, config):
        self.model = model
        self.tokenizer = tokenizer
        self.config = config
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model.to(self.device)
        
    def train(self, train_dataset, epochs=1, batch_size=4, learning_rate=5e-5):
        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
        optimizer = torch.optim.AdamW(self.model.parameters(), lr=learning_rate)
        
        self.model.train()
        total_loss = 0
        steps = 0
        
        print(f"Training on device: {self.device}")
        
        for epoch in range(epochs):
            for batch in train_loader:
                inputs = batch.to(self.device)
                labels = inputs.clone()
                
                optimizer.zero_grad()
                
                # Forward pass
                # Note: We need to adapt the CognitiveProcessingEngine to accept labels or calculate loss here
                # For this PoC, we'll assume the base model (DialoGPT/GPT2) handles LM loss if we pass labels
                # But since we wrap it, we might need to extract the base model or manually calc loss
                
                outputs = self.model.base_model(input_ids=inputs, labels=labels)
                loss = outputs.loss
                
                loss.backward()
                optimizer.step()
                
                total_loss += loss.item()
                steps += 1
                
                if steps % 10 == 0:
                    print(f"Epoch {epoch+1}/{epochs} | Step {steps} | Loss: {loss.item():.4f}")
                    
        return {'final_loss': total_loss / steps if steps > 0 else 0}

# Add fine-tuning method to ASIBrainSystem
def fine_tune_on_data(self, data_path: str, epochs: int = 1) -> Dict:
    """Fine-tune the system on a text file"""
    dataset = TextDataset(data_path, self.cognitive_engine.tokenizer, block_size=self.config.get('max_length', 128))
    trainer = ASITrainer(self.cognitive_engine, self.cognitive_engine.tokenizer, self.config)
    
    logger.info(f"Starting fine-tuning on {data_path} for {epochs} epochs")
    stats = trainer.train(dataset, epochs=epochs)
    
    # Save the model (optional POC implementation)
    # torch.save(self.cognitive_engine.state_dict(), "asi_finetuned.pt")
    
    return stats

# Monkey patch the method into the class for the POC (or usually we'd define it inside)
ASIBrainSystem.fine_tune_on_data = fine_tune_on_data
                    except ValueError:
                        pass
        
        except KeyboardInterrupt:
            break
        except Exception as e:
            print(f"Error: {e}")
    
    print("\nðŸ‘‹ Thanks for using ASI Brain System!")
